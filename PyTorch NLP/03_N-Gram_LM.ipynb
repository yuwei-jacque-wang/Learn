{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-ngram_lms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txr08HTBTBcc"
      },
      "source": [
        "# Fall 2020: DS-GA 1011 NLP with Representation Learning\n",
        "## Lab 3: 18-Sep-2020, Friday\n",
        "## N-Gram Language Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W7Va58r_su2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318a4dc9-8dda-49c5-9610-a405e2db5300"
      },
      "source": [
        "# !conda install -c conda-forge jsonlines #OR\n",
        "!pip install jsonlines"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNviidVu_su6"
      },
      "source": [
        "# Import required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import defaultdict\n",
        "from pprint import pprint\n",
        "import jsonlines\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(1011)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psRISlQv_su-"
      },
      "source": [
        "cf.\n",
        "> `pprint` Prints (â€œpretty-printâ€) the formatted representation of object followed by a newline.\n",
        "\n",
        "> [`defaultdict`](https://docs.python.org/3.7/library/collections.html#collections.defaultdict) a subclass of the built-in `dict` class that makes it simpler and faster to create dictionary of iterables\n",
        "\n",
        "> [`jsonlines`](https://pypi.org/project/jsonlines/) library to simplify working with JSON Lines text (newline-delimited JSON) format\n",
        "\n",
        "> [`matplotlib`](https://matplotlib.org/3.3.1/index.html) visualization library for Python. `pyplot` provides simple interface for generating interactive plot programmaticaly\n",
        "\n",
        "> [`itertools`](https://docs.python.org/3.7/library/itertools.html) module for implementing objects representing stream of data ($\\texttt{iterator}$). `product` results in a cartesian product of input iterables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9OTmBK8_su_"
      },
      "source": [
        "---\n",
        "### N-gram Language Modeling\n",
        "\n",
        "Recall that we want to model the probability of variable length sequences, $$p(w_1,\\ldots,w_T)=\\prod_{t=1}^T p(w_t|w_{<t}).$$\n",
        "\n",
        "An **n-gram language model** assumes that each word $w_t$ only depends on the preceding $n-1$ words, $$p(w_1,\\ldots,w_T)=\\prod_{t=1}^T p(w_t|w_{t-n+1},\\ldots,w_{t-1}).$$\n",
        "\n",
        "We will abbreviate the preceding $n-1$ words as $w_{t-n+1}^{t-1}$. \n",
        "\n",
        "#### Example\n",
        "For instance, when modeling the sentence $$\\texttt{the cat sat on the mat .}$$ a 3-gram language model assumes that $$p(\\texttt{mat}|\\texttt{the cat sat on the}) \\approx p(\\texttt{mat}|\\texttt{on the}).$$\n",
        "\n",
        "The sub-sequence $(\\texttt{on the mat})$ is a *3-gram* or *trigram*.\n",
        "\n",
        "#### Estimation\n",
        "\n",
        "Given some dataset $D$ of sequences, we can estimate an n-gram model through counting, derived as follows:\n",
        "\n",
        "\\begin{align}\n",
        "p(w_t|w_{t-n+1},\\ldots,w_{t-1}) &= \\frac{p(w_{t-n+1},\\ldots,w_t)}{p(w_{t-n+1},\\ldots,w_{t-1})} & \\text{definition of conditional probability}\\\\\n",
        "                       &= \\frac{p(w_{t-n+1},\\ldots,w_t)}{\\sum_{w_{t'}}p(w_{t-n+1},\\ldots,w_{t-1},w_{t'})}\\\\\n",
        "                       &\\approx \\frac{\\frac{1}{N}\\text{count}(w_{t-n+1},\\ldots,w_t)}{\\frac{1}{N}\\sum_{w_{t'}}\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})}\\\\\n",
        "                       &= \\frac{\\text{count}(w_{t-n+1},\\ldots,w_t)}{\\sum_{w_{t'}}\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})}\\\\\n",
        "                       &= \\frac{\\text{count}(w_{t-n+1},\\ldots,w_t)}{\\text{count}(w_{t-n+1},\\ldots,w_{t-1})},\n",
        "\\end{align}\n",
        "\n",
        "where $N$ is the number of $n$-grams in the dataset.\n",
        "\n",
        "In Python, we can collect these counts into a dictionary mapping a prefix to a dictionary of counts:\n",
        "\n",
        "        count[(w_n+1,...,w_t-1)] = {wt1: count of (w_n+1,...,w_t1),\n",
        "                                    wt2: count of (w_n+1,...,w_t2),\n",
        "                                    ...\n",
        "                                   }\n",
        "                                   \n",
        "and for the denominator, maintain a dictionary of totals:\n",
        "\n",
        "        total[(w_n+1,...,w_t-1)] = count of w_n+1,...,w_t-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkEt32Vt_su_"
      },
      "source": [
        "---\n",
        "### Simplified Language\n",
        "\n",
        "To get intuition, lets start by modeling a simple language called `ABC`. A word in this language is one of three tokens, $$w\\in \\{\\texttt{A, B, C}\\},$$\n",
        "and we'll denote a sentence as $\\textbf{s}=(w_1,\\ldots,w_{|\\textbf{w}|})$.\n",
        "\n",
        "\n",
        "Suppose we are given the following dataset, and want to estimate a **bigram model**: $$p(\\textbf{s})\\approx\\prod_{t=1}^{|\\textbf{w}|}p(w_t|w_{t-1})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0uuEu4s_svA"
      },
      "source": [
        "data_raw = [['A', 'A', 'B', 'B'],\n",
        "            ['A', 'A', 'B'],\n",
        "            ['A', 'A', 'B', 'C'],\n",
        "            ['A', 'A', 'A'],\n",
        "            ['A', 'A', 'A', 'A']]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4UIhb4b_svD"
      },
      "source": [
        "To make the model meaningful for $t = 1$ we pad the sentences with an additional **beginning token**, `<bos>`. \n",
        "\n",
        "Since our model is a probability distribution, the total probability of all possible strings in the language must sum to 1, i.e.: $$\\sum_{\\textbf{s}}p(\\textbf{s})=1.$$\n",
        "\n",
        "In order to satisfy this criterion we need an additional **end token**, `<eos>`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUCJzK2c_svD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b04044c-5247-415a-b001-9f02b6fd5ab1"
      },
      "source": [
        "data = [['<bos>'] + d + ['<eos>'] for d in data_raw]\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<bos>', 'A', 'A', 'B', 'B', '<eos>'],\n",
              " ['<bos>', 'A', 'A', 'B', '<eos>'],\n",
              " ['<bos>', 'A', 'A', 'B', 'C', '<eos>'],\n",
              " ['<bos>', 'A', 'A', 'A', '<eos>'],\n",
              " ['<bos>', 'A', 'A', 'A', 'A', '<eos>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMnOlrYT_svH"
      },
      "source": [
        "Now let's estimate a bigram model:\n",
        "\n",
        "\\begin{align}\n",
        "p(w_t|w_{t-1}) &= \\frac{\\text{count}(w_{t-1}w_{t})}{\\sum_{w_{t'}}\\text{count}(w_{t-1}w_{t'})}\\\\\n",
        "               &= \\texttt{count[prefix][wt] / totals[prefix]}\n",
        "\\end{align} \n",
        "\n",
        "where $\\texttt{prefix}$ is $w_{t-1}$ in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv0gjvdH_svI"
      },
      "source": [
        "count = defaultdict(lambda: defaultdict(float))\n",
        "total = defaultdict(float)\n",
        "\n",
        "n = 2\n",
        "for sequence in data:\n",
        "    for i in range(len(sequence)-n+1):         # for each ngram\n",
        "        ngram = tuple(sequence[i:i+n])\n",
        "        prefix, word = ngram[:-1], ngram[-1]\n",
        "        count[prefix][word] += 1               # count(w_{t-n+1}...w_t)\n",
        "        total[prefix] += 1                     # count(w_{t-n+1}...w_{t-1})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDu7Bx9v_svL"
      },
      "source": [
        "cf.\n",
        "> `lambda` lambda expressions (or forms) are used to create anonymous functions. The expression `lambda parameters: expression` yields a function object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYYr75QR_svL"
      },
      "source": [
        "Let's see if the counts and totals make sense:\n",
        "\n",
        "- How many times did (A, B) occur? What about (B, B)?\n",
        "- How many times did (A) occur? What about (C)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dob77m66_svM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52442118-c2a9-4339-996c-c635ecf461b9"
      },
      "source": [
        "print(\"Counts:\")\n",
        "print(dict(count))\n",
        "print(\"\\nTotals:\")\n",
        "print(dict(total))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counts:\n",
            "{('<bos>',): defaultdict(<class 'float'>, {'A': 5.0}), ('A',): defaultdict(<class 'float'>, {'A': 8.0, 'B': 3.0, '<eos>': 2.0}), ('B',): defaultdict(<class 'float'>, {'B': 1.0, '<eos>': 2.0, 'C': 1.0}), ('C',): defaultdict(<class 'float'>, {'<eos>': 1.0})}\n",
            "\n",
            "Totals:\n",
            "{('<bos>',): 5.0, ('A',): 13.0, ('B',): 4.0, ('C',): 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWRm9lW7_svQ"
      },
      "source": [
        "#### Conditional probability queries\n",
        "\n",
        "We can now query a conditional probability:\n",
        "\n",
        "\\begin{align}\n",
        "\\texttt{p(word|prefix)} &= \\texttt{count[prefix][word] / totals[prefix]}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxV_fNRp_svQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d765207-21ff-4640-99bb-0c2032627518"
      },
      "source": [
        "queries = [('<bos>', 'A'),\n",
        "           ('B', 'C')]\n",
        "\n",
        "for query in queries:\n",
        "    prefix, word = query[:-1], query[-1]\n",
        "    p = count[prefix][word] / total[prefix]  # We'll discuss the case when `total[prefix] = 0` below.\n",
        "    print(\"p( %s | %s) = \\t%.5f\" % (word, ', '.join(prefix), p))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p( A | <bos>) = \t1.00000\n",
            "p( C | B) = \t0.25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6Qhxs8R_svT"
      },
      "source": [
        "**Exercise**: Look at the training set and convince yourself that these conditional probabilities are correct according to the count-based estimation procedure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odu38DgT_svU"
      },
      "source": [
        "#### Sequence Probability\n",
        "\n",
        "We can compute the probability of a sequence using the conditional probabilities along with the chain rule:\n",
        "\n",
        "\\begin{align}\n",
        "p(w_1,\\ldots,w_T)&\\approx\\prod_{t=1}^T p(w_t|w_{t-1})\n",
        "\\end{align}\n",
        "\n",
        "(Here $w_0$ is `<bos>` and $w_T$ is `<eos>`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGadntXF_svU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47bcdf44-34ba-4daf-e7b0-0ff107c1a170"
      },
      "source": [
        "sequence = ['<bos>', 'A', 'A', 'B', '<eos>']\n",
        "\n",
        "def sequence_p(sequence, log=False):\n",
        "    total_p = 1\n",
        "\n",
        "    for i in range(len(sequence)-n+1):\n",
        "        ngram = tuple(sequence[i:i+n])\n",
        "        prefix = ngram[:-1]\n",
        "        word = ngram[-1]\n",
        "        p = count[prefix][word] / max(total[prefix], 1)\n",
        "        if log:\n",
        "            print(\"p(%s | %s) =\\t%.3f\" % (word, ', '.join(prefix), p))\n",
        "\n",
        "        total_p *= p\n",
        "    return total_p\n",
        "    \n",
        "\n",
        "print(\"\\nProduct: p(%s) = %.3f\" % (''.join(sequence[1:-1]), sequence_p(sequence, log=True)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p(A | <bos>) =\t1.000\n",
            "p(A | A) =\t0.615\n",
            "p(B | A) =\t0.231\n",
            "p(<eos> | B) =\t0.500\n",
            "\n",
            "Product: p(AAB) = 0.071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ_nr0uH_svX"
      },
      "source": [
        "---\n",
        "### Real Example: Dialogue Utterances\n",
        "\n",
        "Now lets use the same ideas on a more realistic text corpus.\n",
        "\n",
        "We will use utterances from a dialogue dataset called **Persona-Chat**. This dataset is relatively small and centers on a single domain, but it is simple and interpretable for our purposes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40OAXKgS_svX"
      },
      "source": [
        "#### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mq87QkeGo_-",
        "outputId": "7dafbe55-fddd-4d37-cd9e-cb870c245d8b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRbjY9r_WYi5"
      },
      "source": [
        "path = \"/content/drive/My Drive/NLP Lab/Lab 3/\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIeF4g0-_svY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7926ca4-4709-4bfc-f0c1-d4644eb08d19"
      },
      "source": [
        "train = []\n",
        "val = []\n",
        "\n",
        "for ds, name in [(train, 'train'), (val, 'valid')]:\n",
        "    for line in jsonlines.Reader(open(path+'data/personachat/personachat_all_sentences_%s.jsonl' % name, 'r')):\n",
        "        ds.append(line['tokens'])\n",
        "        \n",
        "vocab = list(set([t for ts in train for t in ts]))      \n",
        "print(\"Number of train examples: %d\" % (len(train)))\n",
        "print(\"Number of valid examples: %d\" % (len(val)))\n",
        "print(\"Vocab size: %d\" % (len(vocab)))\n",
        "\n",
        "print(\"\\nExamples:\")\n",
        "pprint(train[:3])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train examples: 133176\n",
            "Number of valid examples: 16181\n",
            "Vocab size: 19153\n",
            "\n",
            "Examples:\n",
            "[['i', 'am', 'doing', 'great', 'except', 'for', 'the', 'allergies', '.'],\n",
            " ['i', 'am', 'a', 'woman', 'what', 'about', 'you', '.'],\n",
            " ['i', 'thought', 'you', 'were', 'a', 'college', 'kid', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWH4C0jk_svc"
      },
      "source": [
        "#### Estimate a **3-gram** model\n",
        "\n",
        "We will use the same approach as in the `ABC` example, except for a 3-gram model.\n",
        "\n",
        "Notice that we now prepend 2 `<bos>` tokens, so that the first conditional probability is `p(first_word|<bos>, <bos>)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5ZOaFyP_svc"
      },
      "source": [
        "count = defaultdict(lambda: defaultdict(float))\n",
        "total = defaultdict(float)\n",
        "\n",
        "n = 3\n",
        "\n",
        "for sequence_raw in train:\n",
        "    sequence = ['<bos>']*(n-1) + sequence_raw + ['<eos>']\n",
        "    for i in range(len(sequence)-n+1):\n",
        "        ngram = tuple(sequence[i:i+n])\n",
        "        prefix, word = ngram[:-1], ngram[-1]\n",
        "\n",
        "        count[prefix][word] += 1\n",
        "        total[prefix] += 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaoQh1Ph_svf"
      },
      "source": [
        "#### Counts\n",
        "\n",
        "Let's check some of the counts for a few trigrams, by querying bigrams and finding the next-words with the highest counts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgC2CPLk_svf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35874bf7-2c73-4659-904e-ea317ce0d3a7"
      },
      "source": [
        "bigram = ('i', 'have')\n",
        "limit = 10\n",
        "\n",
        "for w, c in sorted(count[bigram].items(), key=lambda x: -x[1])[:limit]:\n",
        "    print(\"(%s, %s, %s) -> %.1f\" % (bigram[0], bigram[1], w, c))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(i, have, a) -> 2092.0\n",
            "(i, have, been) -> 740.0\n",
            "(i, have, to) -> 567.0\n",
            "(i, have, never) -> 531.0\n",
            "(i, have, not) -> 484.0\n",
            "(i, have, two) -> 335.0\n",
            "(i, have, no) -> 191.0\n",
            "(i, have, 2) -> 175.0\n",
            "(i, have, 3) -> 163.0\n",
            "(i, have, one) -> 161.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acAC08FX_svi"
      },
      "source": [
        "**Exercise:** How many times does `my pet dog` occur in the training set? What about `my pet lion`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g35lfP-i_svj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9128b68-5964-415f-b574-55548859a421"
      },
      "source": [
        "count[('my', 'pet')]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(float,\n",
              "            {'.': 6.0,\n",
              "             '?': 1.0,\n",
              "             'and': 2.0,\n",
              "             'bear': 1.0,\n",
              "             'beta': 2.0,\n",
              "             'cat': 3.0,\n",
              "             'dog': 2.0,\n",
              "             'dogs': 2.0,\n",
              "             'dragon': 1.0,\n",
              "             'iguana': 8.0,\n",
              "             'iguanas': 4.0,\n",
              "             'is': 3.0,\n",
              "             'keeps': 1.0,\n",
              "             'koala': 1.0,\n",
              "             'like': 1.0,\n",
              "             'lizard': 8.0,\n",
              "             'on': 1.0,\n",
              "             'panda': 3.0,\n",
              "             'poodle': 1.0,\n",
              "             'skunk': 5.0,\n",
              "             'snake': 7.0,\n",
              "             'turtles': 1.0,\n",
              "             'was': 1.0,\n",
              "             'zebra': 1.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycJGPMhT_svl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35367d2a-91ee-4de6-f273-b4255e884774"
      },
      "source": [
        "bigram = ('my', 'pet')\n",
        "limit = 15\n",
        "\n",
        "for w, c in sorted(count[bigram].items(), key=lambda x: x[1])[:limit]:\n",
        "    print(\"(%s, %s, %s) -> %.1f\" % (bigram[0], bigram[1], w, c))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(my, pet, on) -> 1.0\n",
            "(my, pet, like) -> 1.0\n",
            "(my, pet, zebra) -> 1.0\n",
            "(my, pet, was) -> 1.0\n",
            "(my, pet, poodle) -> 1.0\n",
            "(my, pet, turtles) -> 1.0\n",
            "(my, pet, ?) -> 1.0\n",
            "(my, pet, dragon) -> 1.0\n",
            "(my, pet, keeps) -> 1.0\n",
            "(my, pet, bear) -> 1.0\n",
            "(my, pet, koala) -> 1.0\n",
            "(my, pet, dog) -> 2.0\n",
            "(my, pet, dogs) -> 2.0\n",
            "(my, pet, and) -> 2.0\n",
            "(my, pet, beta) -> 2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDLugs9j_svo"
      },
      "source": [
        "#### Conditional probability queries\n",
        "We can now query the model for conditional probabilities:\n",
        "\n",
        "\\begin{align}\n",
        "p(w_t|w_{t-2},w_{t-1}) &= \\frac{\\text{count}(w_{t-2}w_{t-1}w_t)}{\\sum_{w_{t'}}\\text{count}(w_{t-2}w_{t-1}w_{t'})},\n",
        "\\end{align} "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3KpGzIM_svo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f782cfcf-8368-4335-ae04-7c75d3f14924"
      },
      "source": [
        "total[('i', 'have')]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9034.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj0STHYj_svr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3add68c3-5427-4be9-850e-6b744121f8c2"
      },
      "source": [
        "queries = [('i', 'have', 'a'),\n",
        "           ('i', 'have', 'no'),\n",
        "           ('my', 'name', 'is'),\n",
        "           ('my', 'pet', 'dog'),\n",
        "           ('my', 'pet', 'zebra'),\n",
        "           ('my', 'pet', 'lion')]\n",
        "\n",
        "for query in queries:\n",
        "    prefix, word = query[:-1], query[-1]\n",
        "    p = count[prefix][word] / max(total[prefix], 1)\n",
        "    print(\"p( %s | %s) = \\t%.5f\" % (word, ', '.join(prefix), p))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p( a | i, have) = \t0.23157\n",
            "p( no | i, have) = \t0.02114\n",
            "p( is | my, name) = \t0.93409\n",
            "p( dog | my, pet) = \t0.03030\n",
            "p( zebra | my, pet) = \t0.01515\n",
            "p( lion | my, pet) = \t0.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5opdHBO_svu"
      },
      "source": [
        "#### Sequence probabilities:\n",
        "\\begin{align}\n",
        "p(w_1,\\ldots,w_T)&\\approx\\prod_{t=1}^T p(w_t|w_{t-2},w_{t-1})\\\\\n",
        "&=\\sum_{t=1}^T \\log p(w_t|w_{t-2},w_{t-1}).\n",
        "\\end{align}\n",
        "\n",
        "where we use log probabilities in practice to avoid a product of many small numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qg_sRlW_svu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6e20c9-4fe5-4deb-9495-90d5138569fd"
      },
      "source": [
        "padded_sequence = ['<bos>']*(n-1) + train[0] + ['<eos>']\n",
        "print(padded_sequence)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<bos>', '<bos>', 'i', 'am', 'doing', 'great', 'except', 'for', 'the', 'allergies', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX42Nd42_svw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be598072-6382-4aff-91b5-0effdc2e19a5"
      },
      "source": [
        "total_logp = 0\n",
        "\n",
        "for i in range(len(padded_sequence)-n+1):\n",
        "    ngram = tuple(padded_sequence[i:i+n])\n",
        "    prefix = ngram[:-1]\n",
        "    word = ngram[-1]\n",
        "    logp = np.log2(count[prefix][word] / max(total[prefix], 1))\n",
        "    print(\"log p(%s | %s) =\\t%.3f\" % (word, ', '.join(prefix), logp))\n",
        "    \n",
        "    total_logp += logp\n",
        "    \n",
        "print(\"\\nTotal: %.3f\" % total_logp)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log p(i | <bos>, <bos>) =\t-1.631\n",
            "log p(am | <bos>, i) =\t-1.969\n",
            "log p(doing | i, am) =\t-4.455\n",
            "log p(great | am, doing) =\t-2.359\n",
            "log p(except | doing, great) =\t-8.205\n",
            "log p(for | great, except) =\t0.000\n",
            "log p(the | except, for) =\t-2.644\n",
            "log p(allergies | for, the) =\t-9.671\n",
            "log p(. | the, allergies) =\t-0.415\n",
            "log p(<eos> | allergies, .) =\t-0.363\n",
            "\n",
            "Total: -31.710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o058NM_r_svz"
      },
      "source": [
        "**Exercise**: Which conditional probability above has the highest probability?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUTTCupU_svz"
      },
      "source": [
        "#### Generation\n",
        "\n",
        "Finally, we can generate sentences using the model's conditional distribution:\n",
        "\n",
        "            context = [<bos>, <bos>]\n",
        "            until <eos> is generated:\n",
        "                wt ~ p(wt | context)\n",
        "                context += [wt]\n",
        "                \n",
        "                \n",
        "Here, the `~` symbol stands for sampling from a categorical distribution. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ZigeaT_sv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc1fb00-6655-4295-9990-cdb874d163a5"
      },
      "source": [
        "for n_samples in range(10):\n",
        "    context = ('<bos>', '<bos>')\n",
        "\n",
        "    output = context\n",
        "    while output[-1] != '<eos>':\n",
        "        # Form conditional distribution to sample from\n",
        "        probs, tokens = [], []\n",
        "        for token in count[context]:\n",
        "            p = count[context][token] / total[context]\n",
        "            probs.append(p)\n",
        "            tokens.append(token)\n",
        "        # Sample\n",
        "        wt = np.random.choice(tokens, p=probs) # randomly sample from list (tokens) with probs\n",
        "        output = output + (wt,)\n",
        "        context = context[1:] + (wt,)\n",
        "    \n",
        "    print(' '.join(output))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bos> <bos> my wife was in africa . now . t . have you tried using a racket and ball game . <eos>\n",
            "<bos> <bos> not sure yet . <eos>\n",
            "<bos> <bos> i am a nurse . <eos>\n",
            "<bos> <bos> i ride my bike , that feels . i am guessing you are not you take with me . <eos>\n",
            "<bos> <bos> i travelled the world . <eos>\n",
            "<bos> <bos> interesting ? <eos>\n",
            "<bos> <bos> it is a boy and girl . <eos>\n",
            "<bos> <bos> i like to play board games a lot mostly poems . <eos>\n",
            "<bos> <bos> i like rocks ? <eos>\n",
            "<bos> <bos> hey , good , i could , i wish i can see that from your mother ? that sounds nice but i do anymore . <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yMbFvMK_sv2"
      },
      "source": [
        "**Exercise:** Try different starting contexts.\n",
        "\n",
        "**Exercise:** Use **greedy** decoding, `wt = argmax p(wt | context)`, or another decoding method instead of the categorical sampling from above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p4adWLR_sv2"
      },
      "source": [
        "---\n",
        "### ðŸš¨Issues: Data Sparsity & Generalization ðŸš¨\n",
        "\n",
        "As you might have noticed, the model assigns zero probability to even some reasonable n-grams:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6IHqTSW_sv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1feb38e-54bd-46c6-998b-88d7bdd5fcab"
      },
      "source": [
        "queries = [('my', 'pet', 'dog'),\n",
        "           ('my', 'pet', 'zebra'),\n",
        "           ('my', 'pet', 'lion')]\n",
        "\n",
        "for query in queries:\n",
        "    prefix, word = query[:-1], query[-1]\n",
        "    p = count[prefix][word] / max(total[prefix], 1)\n",
        "    print(\"p( %s | %s) = \\t%.5f\" % (word, ', '.join(prefix), p))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p( dog | my, pet) = \t0.03030\n",
            "p( zebra | my, pet) = \t0.01515\n",
            "p( lion | my, pet) = \t0.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTSrnTfB_sv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0632eb83-5cc6-4b45-9f8c-3d4a37a0b234"
      },
      "source": [
        "count[('my', 'pet')][('<UNK>')]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lGy0zeP_sv8"
      },
      "source": [
        "The tri-gram `my pet lion` never occurred in the corpus, corresponding to zero count and hence zero probability under the model.\n",
        "\n",
        "This is in part an issue of **data sparsity** (given infinite data we'd probably see `my pet lion`), but is also an instance of the **generalization** problem; intuitively, even though the model *has* seen `my pet dog` and `my pet zebra`, it does not form a general notion of `my pet {animal}`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SS92UlQ_sv9"
      },
      "source": [
        "#### Additive smoothing\n",
        "\n",
        "N-gram language models address data sparsity through **smoothing** techniques which re-allocate probability mass, for instance to n-grams with zero counts.\n",
        "\n",
        "A simple (and naive, according to empirical performance) smoothing method is to add a *fixed* 'pseudo-count' $\\delta$ to *every* n-gram:\n",
        "\\begin{align}\n",
        "p(w_t|w_{t-n+1},\\ldots,w_{t-1}) &\\approx \\frac{\\text{count}(w_{t-n+1},\\ldots,w_{t})+ \\delta}{\\sum_{w_{t'}}\\left[\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})+\\delta\\right]}\\\\\n",
        "&= \\frac{\\text{count}(w_{t-n+1},\\ldots,w_{t})+ \\delta}{\\delta|V| + \\sum_{w_{t'}}\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})},\n",
        "\\end{align}\n",
        "\n",
        "where V is the vocabulary.\n",
        "\n",
        "Let's implement this below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUHCRjyT_sv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c30c53d-3f36-4059-98e6-b07aa69f76f7"
      },
      "source": [
        "delta = 0.01\n",
        "Vsize = len(vocab)\n",
        "\n",
        "queries = [('my', 'pet', 'dog'),\n",
        "           ('my', 'pet', 'zebra'),\n",
        "           ('my', 'pet', 'lion')]\n",
        "\n",
        "for query in queries:\n",
        "    prefix, word = query[:-1], query[-1]\n",
        "    \n",
        "    ### note the ADDITIVE SMOOTHING â†“\n",
        "    p = (delta + count[prefix][word]) / (total[prefix] + delta*Vsize)\n",
        "    \n",
        "    print(\"p( %s | %s) = \\t%.5f\" % (word, ', '.join(prefix), p))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p( dog | my, pet) = \t0.00780\n",
            "p( zebra | my, pet) = \t0.00392\n",
            "p( lion | my, pet) = \t0.00004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqFvmdPn_swA"
      },
      "source": [
        "**Exercise:** How does `p(lion | my, pet)` change as $\\delta$ decreases/increases? What about `p(dog | my, pet)`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alc0eOgp_swB"
      },
      "source": [
        "---\n",
        "### Evaluation\n",
        "\n",
        "#### Perplexity\n",
        "\n",
        "Intuitively, a good model should assign high probabilities to sequences from the 'true' distribution that it is modeling.\n",
        "\n",
        "A common way of quantifying this is with **perplexity**, a metric inversely-proportional to the probability that the model assigns to a set of sequences, e.g. a 'test set':\n",
        "\n",
        "\\begin{align}\n",
        "\\huge \\text{ppl}(p, D) &\\huge = -\\frac{1}{N_{total}}\\log p(D)\n",
        "\\end{align}\n",
        "\n",
        "where $D=\\{(w_1,\\ldots,w_{N_i})_i\\}_{i=1}^M$ is a dataset of $M$ sequences with total length $N_{\\text{total}}=\\sum_{i}N_i$.\n",
        "\n",
        "Intuitively, when measured in exponential form, **_perplexity measures the average rank of the true next-token, when tokens are ordered by the model's conditional probabilities_**. It is defined on $[1,\\infty)$, with 1 being a perfect model (assigning probability 1 to $D$), and a 'worse' model as perplexity increases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOimpyPE_swB"
      },
      "source": [
        "#### Evaluating our model (and variations)\n",
        "\n",
        "To allow for adjusting $n$ and $\\delta$, let's first put the n-gram model estimation and querying from above into a python class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umoTLRXJ_swC"
      },
      "source": [
        "class NGramLM(object):\n",
        "    def __init__(self, n, delta, vocab):\n",
        "        self.n = n\n",
        "        self.delta = delta\n",
        "        self.count = defaultdict(lambda: defaultdict(float))\n",
        "        self.total = defaultdict(float)\n",
        "        self.vocab = vocab\n",
        "        if '<eos>' not in self.vocab:\n",
        "            self.vocab.append('<eos>')\n",
        "        self.vsize = len(vocab)\n",
        "    \n",
        "    def estimate(self, sequences):\n",
        "        for sequence_raw in sequences:\n",
        "            sequence = ['<bos>']*(self.n-1) + sequence_raw + ['<eos>']\n",
        "            for i in range(len(sequence)-self.n+1):\n",
        "                ngram = tuple(sequence[i:i+self.n])\n",
        "                prefix, word = ngram[:-1], ngram[-1]\n",
        "                self.count[prefix][word] += 1\n",
        "                self.total[prefix] += 1\n",
        "                \n",
        "    def sequence_logp(self, sequence_raw):\n",
        "        sequence = ['<bos>']*(self.n-1) + sequence_raw + ['<eos>']\n",
        "        total_logp = 0\n",
        "        for i in range(len(sequence)-self.n+1):\n",
        "            ngram = tuple(sequence[i:i+self.n])\n",
        "            prefix = ngram[:-1]\n",
        "            word = ngram[-1]\n",
        "            logp = np.log2((self.delta + self.count[prefix][word]) / \n",
        "                           (self.total[prefix] + self.delta*self.vsize))\n",
        "            total_logp += logp\n",
        "        return total_logp"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JywFVi0E_swE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33b5cc4-bb99-4587-f43a-6ecfd933c549"
      },
      "source": [
        "lm = NGramLM(n=3, delta=0.0001, vocab=vocab)\n",
        "lm.estimate(train)\n",
        "print(lm.sequence_logp(train[0]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-33.158200479259946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJjcG-WA_swG"
      },
      "source": [
        "Next we'll define a `perplexity` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni9LUkl8_swG"
      },
      "source": [
        "def perplexity(model, sequences):\n",
        "    n_total = 0\n",
        "    logp_total = 0\n",
        "    for sequence in sequences:\n",
        "        logp_total += model.sequence_logp(sequence)\n",
        "        n_total += len(sequence) + 1             # add 1 for <eos>\n",
        "#     ppl = - (1.0 / n_total) * logp_total\n",
        "    ppl = 2 ** (- (1.0 / n_total) * logp_total)  # the log needs to be in base 2!\n",
        "    return ppl"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzY8I7dS_swI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e42f87-7832-4ad1-a196-e78a9bbae621"
      },
      "source": [
        "print(perplexity(lm, [['i', 'have', 'a', 'dog', '.']]))\n",
        "\n",
        "print(perplexity(lm, [['i', 'have', 'a', 'zebra', '.']]))\n",
        "\n",
        "print(perplexity(lm, [['i', 'have', 'a', 'lion', '.']]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.167222880362521\n",
            "14.307400631227289\n",
            "54.29411412205784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2_yvIQg_swM"
      },
      "source": [
        "#### Evaluation\n",
        "\n",
        "Let's evaluate `train` and `val` perplexity for a range of `n` at a fixed `delta`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6eUQmyO_swM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668ba712-d5d8-43e8-dd21-ea6bc36d9d7e"
      },
      "source": [
        "ns = [2, 3, 4]\n",
        "deltas = [0.0001]\n",
        "\n",
        "train_results = {}\n",
        "val_results = {}\n",
        "lms = {}\n",
        "combos = list(product(ns, deltas))\n",
        "for n, d in tqdm(combos, total=len(combos)):\n",
        "    lm = NGramLM(n=n, delta=d, vocab=vocab)\n",
        "    lm.estimate(train)\n",
        "    \n",
        "    lms[n, d] = lm\n",
        "    train_results[n, d] = perplexity(lm, train)\n",
        "    val_results[n, d] = perplexity(lm, val)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:27<00:00,  9.05s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CzWbnzV_swO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3746792b-4ecc-42dc-df4e-b4e8efee5906"
      },
      "source": [
        "ns = [2, 3, 4]\n",
        "deltas = [0.0001]\n",
        "list(product(ns, deltas))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 0.0001), (3, 0.0001), (4, 0.0001)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxmfDINr_swQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "6ed85200-bf7a-4893-876a-99efaedc82a9"
      },
      "source": [
        "print(\"=== Train ===\")\n",
        "df = pd.DataFrame([(k[0], k[1], v) for k, v in train_results.items()], columns=['n', 'delta', 'ppl'])\n",
        "df[df.delta == 0.0001].style.hide_index()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Train ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >n</th>        <th class=\"col_heading level0 col1\" >delta</th>        <th class=\"col_heading level0 col2\" >ppl</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                                <td id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002row0_col0\" class=\"data row0 col0\" >2</td>\n",
              "                        <td id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.000100</td>\n",
              "                        <td id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002row0_col2\" class=\"data row0 col2\" >35.478667</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002row1_col0\" class=\"data row1 col0\" >3</td>\n",
              "                        <td id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.000100</td>\n",
              "                        <td id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002row1_col2\" class=\"data row1 col2\" >12.189784</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002row2_col0\" class=\"data row2 col0\" >4</td>\n",
              "                        <td id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.000100</td>\n",
              "                        <td id=\"T_860ef0bc_f094_11eb_b5be_0242ac1c0002row2_col2\" class=\"data row2 col2\" >7.071077</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f93eb79ba10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txRbifx8_swS"
      },
      "source": [
        "On the **training set**, perplexity **decreased** as n-gram order increased (at a fixed `delta` value).\n",
        "\n",
        "\n",
        "Now, on the validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGs_7qUM_swT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "85e91b01-44ff-4c9a-94df-ee48ed6b8535"
      },
      "source": [
        "print(\"=== Valid ===\")\n",
        "df = pd.DataFrame([(k[0], k[1], v) for k, v in val_results.items()], columns=['n', 'd', 'ppl'])\n",
        "df[df.d == 0.0001].style.hide_index()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Valid ===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >n</th>        <th class=\"col_heading level0 col1\" >d</th>        <th class=\"col_heading level0 col2\" >ppl</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                                <td id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002row0_col0\" class=\"data row0 col0\" >2</td>\n",
              "                        <td id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.000100</td>\n",
              "                        <td id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002row0_col2\" class=\"data row0 col2\" >94.251318</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002row1_col0\" class=\"data row1 col0\" >3</td>\n",
              "                        <td id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.000100</td>\n",
              "                        <td id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002row1_col2\" class=\"data row1 col2\" >196.977312</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                                <td id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002row2_col0\" class=\"data row2 col0\" >4</td>\n",
              "                        <td id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.000100</td>\n",
              "                        <td id=\"T_8a374158_f094_11eb_b5be_0242ac1c0002row2_col2\" class=\"data row2 col2\" >601.984842</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f93eaa29a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjdATtxU_swV"
      },
      "source": [
        "Next we can plot **performance as `delta` varies**.\n",
        "\n",
        "(for efficiency we'll simply modify the `.delta` parameter instead of creating a new model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYu7dSQ8_swW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39384dd2-d53f-49c8-cfd4-7f0aea302eed"
      },
      "source": [
        "ns = [2, 3, 4]\n",
        "deltas = np.linspace(0.00001, 0.01, 10)\n",
        "\n",
        "T = np.zeros((len(ns), len(deltas)))\n",
        "V = np.zeros((len(ns), len(deltas)))\n",
        "\n",
        "for i, n in tqdm(enumerate(ns), total=len(ns)):\n",
        "    lm = lms[n, 0.0001]\n",
        "    for j, delta in enumerate(deltas):\n",
        "        lm.delta = delta\n",
        "        \n",
        "        T[i, j] = perplexity(lm, train)\n",
        "        V[i, j] = perplexity(lm, val)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:02<00:00, 80.71s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN6MP8Wh_swY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "4f47d2e0-0b16-46a5-d28a-5f1bac641c7f"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
        "for i in range(len(ns)):\n",
        "    axs[0].plot(T[i])\n",
        "    axs[1].plot(V[i])\n",
        "    \n",
        "axs[0].set_title(\"Train Perplexity\", fontsize=15)\n",
        "axs[1].set_title(\"Val Perplexity\", fontsize=15)\n",
        "\n",
        "axs[0].set_xticks(np.arange(len(deltas)))\n",
        "axs[1].set_xticks(np.arange(len(deltas)))\n",
        "\n",
        "axs[0].set_xticklabels(['{:.1e}'.format(x) for x in deltas], rotation=90)\n",
        "axs[1].set_xticklabels(['{:.1e}'.format(x) for x in deltas], rotation=90)\n",
        "\n",
        "axs[0].set_xlabel('delta', fontsize=15)\n",
        "axs[1].set_xlabel('delta', fontsize=15)\n",
        "\n",
        "axs[0].set_ylabel('ppl', fontsize=15)\n",
        "axs[1].set_ylabel('ppl', fontsize=15)\n",
        "\n",
        "plt.legend(ns, fontsize=15);"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmR0yleB_swa"
      },
      "source": [
        "### Scoring Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6S6aWy_swb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07fa7dd6-ed48-4cfb-c35c-498847c2a17c"
      },
      "source": [
        "sentences = [\n",
        "    'i like my pet dog .',\n",
        "    'i like my pet zebra .',\n",
        "    'i like my pet lion .',\n",
        "    'i live in the united states .',\n",
        "    'i live in the united states of america .'\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    print(sentence)\n",
        "    for n in [2, 3, 4]:\n",
        "        logp = lms[n, 0.0001].sequence_logp(sentence.split())\n",
        "        print(\"n: %d\\t logp: %.3f\" % (n, logp))\n",
        "    print()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i like my pet dog .\n",
            "n: 2\t logp: -29.697\n",
            "n: 3\t logp: -35.726\n",
            "n: 4\t logp: -54.898\n",
            "\n",
            "i like my pet zebra .\n",
            "n: 2\t logp: -34.919\n",
            "n: 3\t logp: -42.678\n",
            "n: 4\t logp: -63.110\n",
            "\n",
            "i like my pet lion .\n",
            "n: 2\t logp: -40.617\n",
            "n: 3\t logp: -54.717\n",
            "n: 4\t logp: -69.753\n",
            "\n",
            "i live in the united states .\n",
            "n: 2\t logp: -26.129\n",
            "n: 3\t logp: -27.717\n",
            "n: 4\t logp: -29.649\n",
            "\n",
            "i live in the united states of america .\n",
            "n: 2\t logp: -44.935\n",
            "n: 3\t logp: -43.757\n",
            "n: 4\t logp: -49.340\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lpzzKrU_swd"
      },
      "source": [
        "---\n",
        "## References\n",
        "DS-GA 1011 NLP with Representation Learning Fall 2019"
      ]
    }
  ]
}